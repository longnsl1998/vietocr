aug:
  image_aug: true
  masked_language_model: true
backbone: vgg19_bn
cnn:
  hidden: 256
  ks:
  - - 2
    - 2
  - - 2
    - 2
  - - 2
    - 1
  - - 2
    - 1
  - - 1
    - 1
  pretrained: true
  ss:
  - - 2
    - 2
  - - 2
    - 2
  - - 2
    - 1
  - - 2
    - 1
  - - 1
    - 1
dataloader:
  num_workers: 1
  pin_memory: true
dataset:
  data_root: /home/longhn
  image_height: 32
  image_max_width: 512
  image_min_width: 32
  name: hw
  train_annotation: /home/longhn/Anotation_0506/train.txt
  valid_annotation: /home/longhn/Anotation_0506/valid.txt
device: cuda
optimizer:
  max_lr: 0.0003
  pct_start: 0.1
predictor:
  beamsearch: false
pretrain:
  cached: /tmp/tranformerorc.pth
  id_or_url: 13327Y1tz1ohsm5YZMyXVMPIOjoOA0OaA
  md5: af6b46e9295eb1c27ca90bddf8c8729a
quiet: false
seq_modeling: transformer
trainer:
  batch_size: 32
  checkpoint: checkpoint/transfomer_0706_pretrain_32_130k.pth
  export: checkpoint/transfomer_0706_pretrain_32_130k.pth
  iters: 300000
  log: ./train.log
  metrics: 15000
  print_every: 200
  valid_every: 2000
transformer:
  d_model: 256
  dim_feedforward: 2048
  max_seq_length: 1024
  nhead: 8
  num_decoder_layers: 6
  num_encoder_layers: 6
  pos_dropout: 0.1
  trans_dropout: 0.1
vocab: 'aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐÐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0123456789!"#$%&''()*+,-./:;<=>?@[\]^_`{|}~ '
weights: https://drive.google.com/uc?id=13327Y1tz1ohsm5YZMyXVMPIOjoOA0OaA
